{"/news/Lichee/RV/run_nonos_program/nonos_run.html": {"title": "在D1上使用裸机程序", "content": "# 在D1上使用裸机程序\n\n> 编辑于2022.04.29\n\n近日一国内小哥实现了一种在D1上运行裸机程序的方法。让我们一起来看一下吧\n\n<!-- more -->\n\nGithub仓库地址在这里：https://github.com/Ouyancheng/FlatHeadBro\n\n相关使用方法在仓库的 readme 写的很详细了。\n\n大概就是用先编译出一个 启动固件，烧录到SD卡启动板子后可以看到串口有相关的信息打印出来。\n\n接着只需要将想要运行的程序使用python通过串口传送到开发板上面即可。"}, "/news/Lichee/RV/D1-ncnn/D1_ncnn_new.html": {"title": "又在全志d1开发板上玩ncnn", "content": "---\ntitle: 又在全志d1开发板上玩ncnn\nkeywords: D1, RV, Lichee, ncnn, \ndesc: 又在全志d1开发板上玩ncnn\ndate: 2022-03-28\ntags: RV, ncnn\n---\n\n\n<!-- more -->\n\n转载自知乎用户 [nihui](https://www.zhihu.com/people/nihui-2) [原文链接](https://zhuanlan.zhihu.com/p/441176926)，原文写于 2021-07-03\n\n又在全志d1开发板上玩ncnn\n\n**可在不修改本文章内容和banner图前提下，转载本文**\n\n## 0x0 工具链变得更好了\n距上次[在全志d1开发板上玩ncnn](./D1_ncnn.html)，已经过去了5个月\n\n在此期间，ncnn收到perfxlab和腾讯犀牛鸟开源人才的学生有关riscv vector的优化\n\n但更重要的是，平头哥收到了社区的反馈，提供了新版工具链\n\n- 支持了 risc-v vector intrinsic v1.0\n- 修复了 release 模式编译 ncnn 时的非法指令问题\nhttps://occ.t-head.cn/community/download?id=3987221940543754240\n\n旧版本工具链的 gcc 比较笨，经常做些负优化，于是试试全新的工具链\n\n## 0x1 配置新的 cmake toolchain\n```bash\n旧\n-march=rv64gcvxtheadc -mabi=lp64d -mtune=c906 -DRVV_SPEC_0_7 -D__riscv_zfh=1 -static\n\n新\n-march=rv64gcv0p7_zfh_xtheadc -mabi=lp64d -mtune=c906 -static\n```\n- arch 参数要用 v0p7，不能用默认的 v，否则会生成非法指令\n- 删除 -DRVV_SPEC_0_7，开启 ncnn 的 rvv-1.0 intrinsic 代码\n- 删除 -D__riscv_zfh=1，arch 参数的 zfh 中已经指代\n\n放在 ncnn/toolchains/c906-v222.toolchain.cmake\n\n## 0x2 工具链修复\n\n因为 rvv-0.7 缺少某些指令支持，遇到一些 rvv-1.0 的代码会生成 unknown op\n```bash\nfneg\nfrec7\nfrsqrt7\n```\n因此要修改下工具链头文件\n\n打开 Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.2.2/lib/gcc/riscv64-unknown-linux-gnu/10.2.0/include/riscv_vector.h\n\n- 找到以下三行\n```h\n_RVV_FLOAT_ITERATOR_ARG (_RVV_FLOAT_UNARY_OP, rec7)\n_RVV_FLOAT_ITERATOR_ARG (_RVV_FLOAT_UNARY_OP, rsqrt7)\n_RVV_FLOAT_ITERATOR_ARG (_RVV_FLOAT_UNARY_OP, neg)\n```\n- 注释掉\n\n```h\n// _RVV_FLOAT_ITERATOR_ARG (_RVV_FLOAT_UNARY_OP, rec7)\n// _RVV_FLOAT_ITERATOR_ARG (_RVV_FLOAT_UNARY_OP, rsqrt7)\n// _RVV_FLOAT_ITERATOR_ARG (_RVV_FLOAT_UNARY_OP, neg)\n```\n\n- 找到文件末尾的三个 #endif，添加以下兼容代码，保存\n\n```h\n#endif\n\n#define vfneg_v_f32m1(x, vl) vfsgnjn_vv_f32m1(x, x, vl)\n#define vfneg_v_f32m2(x, vl) vfsgnjn_vv_f32m2(x, x, vl)\n#define vfneg_v_f32m4(x, vl) vfsgnjn_vv_f32m4(x, x, vl)\n#define vfneg_v_f32m8(x, vl) vfsgnjn_vv_f32m8(x, x, vl)\n#define vfneg_v_f16m1(x, vl) vfsgnjn_vv_f16m1(x, x, vl)\n#define vfneg_v_f16m2(x, vl) vfsgnjn_vv_f16m2(x, x, vl)\n#define vfneg_v_f16m4(x, vl) vfsgnjn_vv_f16m4(x, x, vl)\n#define vfneg_v_f16m8(x, vl) vfsgnjn_vv_f16m8(x, x, vl)\n\n#define vfrec7_v_f32m1(x, vl) vfrdiv_vf_f32m1(x, 1.f, vl)\n#define vfrec7_v_f32m2(x, vl) vfrdiv_vf_f32m2(x, 1.f, vl)\n#define vfrec7_v_f32m4(x, vl) vfrdiv_vf_f32m4(x, 1.f, vl)\n#define vfrec7_v_f32m8(x, vl) vfrdiv_vf_f32m8(x, 1.f, vl)\n#define vfrec7_v_f16m1(x, vl) vfrdiv_vf_f16m1(x, 1.f, vl)\n#define vfrec7_v_f16m2(x, vl) vfrdiv_vf_f16m2(x, 1.f, vl)\n#define vfrec7_v_f16m4(x, vl) vfrdiv_vf_f16m4(x, 1.f, vl)\n#define vfrec7_v_f16m8(x, vl) vfrdiv_vf_f16m8(x, 1.f, vl)\n\n#define vfrsqrt7_v_f32m1(x, vl) vfrdiv_vf_f32m1(vfsqrt_v_f32m1(x, vl), 1.f, vl)\n#define vfrsqrt7_v_f32m2(x, vl) vfrdiv_vf_f32m2(vfsqrt_v_f32m2(x, vl), 1.f, vl)\n#define vfrsqrt7_v_f32m4(x, vl) vfrdiv_vf_f32m4(vfsqrt_v_f32m4(x, vl), 1.f, vl)\n#define vfrsqrt7_v_f32m8(x, vl) vfrdiv_vf_f32m8(vfsqrt_v_f32m8(x, vl), 1.f, vl)\n#define vfrsqrt7_v_f16m1(x, vl) vfrdiv_vf_f16m1(vfsqrt_v_f16m1(x, vl), 1.f, vl)\n#define vfrsqrt7_v_f16m2(x, vl) vfrdiv_vf_f16m2(vfsqrt_v_f16m2(x, vl), 1.f, vl)\n#define vfrsqrt7_v_f16m4(x, vl) vfrdiv_vf_f16m4(vfsqrt_v_f16m4(x, vl), 1.f, vl)\n#define vfrsqrt7_v_f16m8(x, vl) vfrdiv_vf_f16m8(vfsqrt_v_f16m8(x, vl), 1.f, vl)\n\n#endif\n#endif\n```\n\n## 下载和编译ncnn\n这次可以用 release 编译啦！\n```bash\ngit clone https://github.com/Tencent/ncnn.git\ncd ncnn\nmkdir build-c906\ncd build-c906\ncmake -DCMAKE_TOOLCHAIN_FILE=../toolchains/c906-v222.toolchain.cmake -DCMAKE_BUILD_TYPE=release -DNCNN_OPENMP=OFF -DNCNN_THREADS=OFF -DNCNN_RUNTIME_CPU=OFF -DNCNN_RVV=ON -DNCNN_SIMPLEOCV=ON -DNCNN_BUILD_EXAMPLES=ON ..\nmake -j32\n```\n\n## 新旧工具链的性能测试对比\n![](./assets/ncnn_new/ncnn_new_001.jpg)\n\n![](./assets/ncnn_new/ncnn_new_002.jpg)\n\n## 0x5 欢迎关注 ncnn github，加qq群交流！\nhttps://github.com/Tencent/ncnn\nqq群在 ncnn github 首页 readme 中～"}, "/news/Lichee/RV/D1-ncnn/D1_ncnn.html": {"title": "在全志d1开发板上玩ncnn", "content": "---\ntitle: 在全志d1开发板上玩ncnn\nkeywords: D1, RV, Lichee, ncnn, \ndesc: 在全志d1开发板上玩ncnn\ndate: 2022-03-28\ntags: RV, ncnn\n---\n\n<!-- more -->\n\n转载自知乎用户 [nihui](https://www.zhihu.com/people/nihui-2) [原文链接](https://zhuanlan.zhihu.com/p/386312071)，原文写于 2021-07-03\n\n在全志d1开发板上玩ncnn\n\n**可在不修改本文章内容和banner图前提下，转载本文**\n```\n这是我最后一次优化 risc-v\n这 1.4w 行代码是我最后的倔强\n你们不可能再看见我为这个 d1 写一行代码，不可能\n这 96 个 cpp 文件，我要用到 2030 年\n```\n**首先感谢全志科技公司送了我d1开发板，以及sipeed、rvboards在系统底层技术工作和支持，才有了ncnn AI推理库在risc-v架构上更好的优化 qwqwqwq**\n\n## 0x0 ncnn risc-v 优化情况\n[ncnn](https://github.com/Tencent/ncnn) 是腾讯开源的神经网络推理框架\n- 支持深度学习模型 caffe/mxnet/keras/pytorch(onnx)/darknet/tensorflow(mlir)\n- 跨平台：Windows/Linux/MacOS/Android/iOS/WebAssembly/...\n- 兼容多种 CPU 架构：x86/arm/mips/risc-v/...\n- 支持 GPU 加速：NVIDIA/AMD/Intel/Apple/ARM-Mali/Adreno/...\n- 支持各种常见的模型结构，比如 mobilenet/shufflenet/resnet/LSTM/SSD/yolo...\n- 很强，qq群请移驾 ncnn github 首页README\n_因为据全（某）志（人）说，全志的用户基础都挺一般，可能不知道 ncnn 是什么东西，所以便罗嗦一番..._\n\n从上次发了开箱自拍jpg，到现在一个月了，ncnn risc-v vector 优化情况还算不错，大部分重要的优化都做了，剩下一些会留给社区学生pr，和慢慢变聪明的编译器\n\nncnn risc-v 目前使用 rvv-1.0 intrinisc 编写优化代码，并支持任意 vlen 的配置，面向未来顺便兼容了 d1开发板\n\n- rvv-0.7.1 某些 intrinisc 转换可能有效率问题\n- 有遇到过 0.7.1 intrinisc 行为怪异只能写 C 代码绕过\n- gcc 还比较笨，每行 intrinisc 都会加一条无用的 setvli 指令\n- 因为没法同时兼容 rvv-1.0 和 rvv-0.7.1，便没有写汇编\n- 一些算子，如 hardswish/hardsigmoid/binaryop/eltwise/slice/... 待优化（欢迎pr！！！qaq）\n下面这张表只是最近一周多的情况。如果跟最开始比，柱状图就太高了...\n![](./assets/ncnn/001.jpg)\n\n![](./assets/ncnn/002.jpg)\n\n## 0x1 准备交叉编译工具链\n去平头哥芯片开放社区下载 工具链-900 系列 \nhttps://occ.t-head.cn/community/download?id=3913221581316624384\n比如 riscv64-linux-x86_64-20210512.tar.gz，下载后解压缩，设置环境变量\n```bash\ntar -xf riscv64-linux-x86_64-20210512.tar.gz\nexport RISCV_ROOT_PATH=/home/nihui/osd/riscv64-linux-x86_64-20210512\n```\n## 0x2 下载和编译ncnn\n\n为 d1 架构交叉编译 ncnn\n\n**因为编译器 bug，release 编译会导致运行时非法指令错误，必须使用 relwithdebinfo 编译哦**\n\n- ncnn 已支持直接用 simpleocv 替代 opencv 编译出 examples\n- **不需要配opencv啦！**\n- **不需要配opencv啦！**\n- **不需要配opencv啦！（重要，说了三遍）**\n\n```bash\ngit clone https://github.com/Tencent/ncnn.git\ncd ncnn\nmkdir build-c906\ncd build-c906\ncmake -DCMAKE_TOOLCHAIN_FILE=../toolchains/c906.toolchain.cmake -DCMAKE_BUILD_TYPE=relwithdebinfo -DNCNN_OPENMP=OFF -DNCNN_THREADS=OFF -DNCNN_RUNTIME_CPU=OFF -DNCNN_RVV=ON -DNCNN_SIMPLEOCV=ON -DNCNN_BUILD_EXAMPLES=ON ..\nmake -j32\n```\n## 0x3 测试benchncnn\n**d1 默认的 TinaLinux 执行 ncnn 程序时会发生非法指令错误，必须使用 Debian 系统哦**\n- vgg16 这类大型模型在内存不足时会发生 segmentation fault，是 d1开发板硬件条件不够，不管即可\n  \n将 `ncnn/build-c906/benchmark/benchncnn` 和 `ncnn/benchmark/*.param` 拷贝到 d1开发板上\n```bash\n./benchncnn 4 1 0 -1 0\n```\n\n## 0x4 测试example\n将 `ncnn/build-c906/examples/nanodet` 和测试图片拷贝到 d1开发板上\n从这里下载 nanodet 模型文件并拷贝到 d1开发板上\nhttps://github.com/nihui/ncnn-assets/tree/master/models\n```bash\n./nanodet test.jpg\n```\n输出检测结果信息，并保存在 image.png\n```\n0 = 0.82324 at 200.04 44.89 198.96 x 253.33\n0 = 0.78271 at 32.98 63.45 178.15 x 232.92\n56 = 0.45923 at 1.46 71.92 90.14 x 117.85\nimshow save image to image.png\nwaitKey stub\n```\n把image.png下载到本地查看，结果已经画在图片上了！d1开发板AI目标检测成功 w\n![](./assets/ncnn/003.jpg)\n\n## 0x5 mips大概也会安排啦，欢迎关注 ncnn github，加qq群交流！\nhttps://github.com/Tencent/ncnn\n\nqq群在 ncnn github 首页 readme 中～"}, "/news/MaixPy/star_maixpy.html": {"title": "MaixPy 上手指南（避坑）之上手篇", "content": "---\ntitle: MaixPy 上手指南（避坑）之上手篇\nkeywords: MaixPy, K210, Python, MicroPython\ndesc: MaixPy 上手指南（避坑） 之上手篇\ndate: 2022-04-01\ntags: MaixPy, K210\n\n---\n\n> 作者：Ray（Rui）\n\n拿到热乎的 K210 开发板，如何上手使用。我接触了许许多多的小白开发者后，整理出来的资料和路线，希望可以减少你们遇到的问题，可以更加愉快的使用 K210 进行自己的项目开发。\n\n<!-- more -->\n\n## K210 开发板\n\n市面上有很多中关于 K210 的开发板，但是并不是所有的开发板都是可以使用 MaixPy 进行开发的。毕竟不同厂商使用的摄像头、屏幕、引脚上使用，都是由差异性的。目前支持的使用 MaixPy 开发的板子有 Sipeed 家的 [Maix 系列](/hardware/zh/maix/index.html)。\n\n如果是试用别家的开发板，并不能很好的兼容 MaixPy，存在差异性。\n\n## 开箱\n\n拿到开发板，首先需要根据屏幕和摄像头排线上的丝印提示来安装好，即排线上的数字 “1” 和板子卡座边上引脚丝印 “1” 方位对应接上。上电之后，屏幕上会显示出一个红色的界面这是开发板已经正常启动了。（也可能存在部分丝印印反）\n\n### 首先要安装开发环境：\n\n1. [【安装驱动】](/soft/maixpy/zh/get_started/env_install_driver.html) 根据自己使用的开发进行选择需要按安装驱动\n2. [【更新固件】](/soft/maixpy/zh/get_started/upgrade_maixpy_firmware.html) 确保使用的是最新版本的固件，并学习一下每个固件之间的[差异](/soft/maixpy/zh/get_started/upgrade_maixpy_firmware.html#固件命名说明)\n3. [【安装 MaixPy IDE】](/soft/maixpy/zh/get_started/env_maixpyide.html) \n\n如果安装驱动的时候出现安装失败，或者是安装驱动之后，电脑上没有显示 COM 口的，就需要更新一下系统或者是检查一下自己的系统是不是正版的了。因为有部分的盗版系统安装不上驱动，或者是安装驱动之后并显示。或者通过换 USB 口进行连接，也许就可以检测到开发板\n\n### 运行代码检测摄像头\n\n将开发板接到电脑上，打开 MaixPy IDE，运行打开的例程代码，检查自己的屏幕和摄像头是否正确连接上了。如果运行例程代码之后，并没有图像出现来屏幕和 IDE 上时，可能摄像头接反了。\n\n## 开始学习使用\n\n开始使用 K210 之前，一定要学习 Python，如果你连 Python 都不会的，就不要继续往下走，可以快速的过一遍 [Python](/soft/maixpy3/zh/origin/python.html) 的语法和使用，一定要会 Python !一定要会 Python !一定要会 Python !\n\n现在就当你懂 Python 了，这是就可以开始看 MaixPy 文档中的[【入门指南】——【上手】](/soft/maixpy/zh/get_started/get_started_power_on.html)，进行对于 MaixPy 的使用和 K210 的基本了解。\n\n[【进阶教程】](/soft/maixpy/zh/course/index.html) 中将有 MaixPy 更多的使用案例和使用方式，一定要确保自己已经对应入门教程中内容已经了解和掌握了再去看，否则你在学习的时候还是会一脸懵逼，不知所云。\n\n## 获取 AI 模型文件\n\n在【进阶教程】中是有讲述如何运行神经网络模型，也知道怎么去获取示例中的模型文件，但是少了如何获取机器码这个操作，这里详细的讲述一下何如获取机器码。\n\n1. 将 [key_gen.bin](https://dl.sipeed.com/fileList/MaixHub_Tools/key_gen_v1.2.bin) 这个固件通过 Kflash 烧录到开发板上。烧录这个机器码固件之后，开发板是处于一个不能使用的状态，上电屏幕只会变成一个白屏。\n2. 这时将开发板通过 USB 连接到电脑上，利用[【串口连接】](/soft/maixpy/zh/get_started/env_serial_tools.html)中的方式来连接开发板。注：IDE 中的串口终端和 IDE 的连接方式相对独立的，而且串口不能通过多种方式进行连接\n3. 利用串口软件连接上开发板，这时按下开发板上的 reset 的按键，就会出现一串字符在终端窗口上，这就机器码。如果机器码\n\n> 推荐使用 IDE 中的 串口终端进行查看，这个相对别的软件更加适合 K210\n\n机器码是一机一码的一种加密方式，用于模型文件的加密。如果使用别的机器码去加密或者下载以 smodel 为文件后缀的模型文件，开发板是无法使用该模型文件的。"}, "/news/MaixPy3/maixpy3_easyuse/maixpy3_easyuse.html": {"title": "MaixPy3 源码怎么样", "content": "---\ntitle: MaixPy3 源码怎么样\nkeywords: V831, Maixpy3\ndate: 2022-04-29\ntags: MaixPy3,QQ\n---\n\n这里只使用一张图来说明一下相关的结论\n\n<!-- more -->\n\n![](./assets/pic.jpg)"}, "/news/MaixPy3/v831_Distance/v831_Distance.html": {"title": "V831完美的单目测距", "content": "---\ntitle: V831完美的单目测距\nkeywords: V831, 单目, 测距\ndate: 2022-03-28\ndesc: V831完美的单目测距\ntags: V83x,单目测距\n---\n\n<!-- more -->\n\n作者[我与nano](https://qichenxi.blog.csdn.net/?type=blog)，[原文链接](https://blog.csdn.net/qq_51963216/article/details/123745657)\n\n## 前言\n\n经过一下午的努力，最终终于实现了完美的单目测距，网上教的都是opencv怎么测算距离，人家有函数唉，入手了V831，做了人脸识别，同时进行了测距，K210通用。废话不多说上图。\n\n![单目测距](./assets/distance_measure.png)\n![摄像头距离](./assets/Camera_length.png)\n它那个镜头其实还要在靠近里面一点，距离应该是28.4到28.5之间。测得真的特别准。\n\n## 单目测距的原理\n![principle](./assets/principle.png)\n\n小孔成像。很简单，用的是小孔成像，原理大家都知道。该怎么做呢。\n我们需要以下几个参数：\n1、相机焦距\n2、物体宽度\n3、一个常数\n\n## 参数计算\n\n### 相机焦距\n假设我们有一个宽度为 W 的目标。然后我们将这个目标放在距离我们的相机为 D 的位置。我们用相机对物体进行拍照并且测量物体的像素宽度 P 。这样我们就得出了相机焦距的公式：\n\nF = (P x D) / W\n\n举个例子，假设我在离相机距离 D = 28cm的地方放一张 待识别图片（W = 13)并且拍下一张照片。我测量出照片的像素宽度为 P = 53 像素\n\n![](./assets/length_calculate.png)\n\n因此我的焦距 F 是：\n\nF = (53*28) / 13 = 116\n\n有人会问像素怎么获得呢，直接看代码吧\n```python\n img.draw_rectangle(box[0], box[1], box[0] + box[2], box[1] + box[3], color=bg_color, thickness=2)\n            img.draw_rectangle(box[0], box[1] - font_wh[1], box[0] + font_wh[0], box[1], color=bg_color, thickness = -1)\n            img.draw_string(box[0], box[1] - font_wh[1], disp_str, color=font_color)\n            img.draw_string(0,30, \"x=\"+str(((box[0]+box[3])/2)-35), color= font_color)\n            img.draw_string(70,30, \"y=\"+str((box[1]+box[2])/2), color= font_color)\n\n            Lm = (box[1]+box[3])/2\n            length = K*13/Lm\n            img.draw_string(0,60 , \"Z=\"+str(length), color= font_color)\n\n```\n你识别到一个物体，然后给它画框，用一个列表表示出来四个点\nLm=（box[1]+box[3]）/2 这个就是像素值\n\n### 测距\n继续将相机移动，靠近或者离远物体或者目标时，可以用相似三角形计算出物体离相机的距离：\nL= (W x F) / P\n假设我将相机移到距离目标 28cm 的地方识别物体。通过自动的图形处理我可以获得图片的像素为 53像素。将这个代入公式，得：\nL= (13 x 116) / 53 = 28\n这样我们就精准的算出了距离。\n\n附上代码\n```python\nfrom maix import camera, image, display\nimport serial\nser = serial.Serial(\"/dev/ttyS1\",115200)    # 连接串口\nK=116\nclass Face_recognize :\n    score_threshold = 70                            #识别分数阈值\n    input_size = (224, 224, 3)                      #输入图片尺寸\n    input_size_fe = (128, 128, 3)                   #输入人脸数据\n    feature_len = 256                               #人脸数据宽度\n    steps = [8, 16, 32]                             #\n    channel_num = 0                                 #通道数量\n    users = []                                      #初始化用户列表\n    threshold = 0.5                                         #人脸阈值\n    nms = 0.3\n    max_face_num = 3                                        #输出的画面中的人脸\n    def __init__(self):\n        from maix import nn, camera, image, display\n        from maix.nn.app.face import FaceRecognize\n        for i in range(len(self.steps)):\n            self.channel_num += self.input_size[1] / self.steps[i] * (self.input_size[0] / self.steps[i]) * 2\n        self.channel_num = int(self.channel_num)     #统计通道数量\nglobal face_recognizer\nface_recognizer = Face_recognize()\nwhile True:\n    img = camera.capture()                       #获取224*224*3的图像数据\n    AI_img = img.copy().resize(224, 224)\n    faces = face_recognizer.face_recognizer.get_faces(AI_img.tobytes(),False)           #提取人脸特征信息\n\n    if faces:\n        for prob, box, landmarks, feature in faces:\n            disp_str = \"face\"\n            bg_color = (0, 255, 0)\n            font_color=(255, 0, 0)\n            box,points = face_recognizer.map_face(box,landmarks)\n            font_wh = image.get_string_size(disp_str)\n            for p in points:\n                img.draw_rectangle(p[0] - 1, p[1] -1, p[0] + 1, p[1] + 1, color=bg_color)\n            img.draw_rectangle(box[0], box[1], box[0] + box[2], box[1] + box[3], color=bg_color, thickness=2)\n            img.draw_rectangle(box[0], box[1] - font_wh[1], box[0] + font_wh[0], box[1], color=bg_color, thickness = -1)\n            img.draw_string(box[0], box[1] - font_wh[1], disp_str, color=font_color)\n            img.draw_string(0,30, \"x=\"+str(((box[0]+box[3])/2-28)), color= font_color)\n            img.draw_string(70,30, \"y=\"+str((box[1]+box[2])/2-20), color= font_color)\n            x=(box[0]+box[3])/2-28\n            y=(box[1]+box[2])/2\n            Lm = (box[1]+box[3])/2\n            length = K*13/Lm\n            img.draw_string(0,60 , \"Z=\"+str(round(length)), color= font_color)\n           \n    display.show(img)\n\n```\n\n## 总结\n\n**主要原理就是小孔成像**"}, "/news/MaixPy3/key_face_recognize.html": {"title": "V831的人脸识别", "content": "---\ntitle: V831的人脸识别\nkeywords: MaixII-Dock, MaixPy3, 人脸识别, V831\ndesc: V831的人脸识别\ndate: 2022-03-15\ntags: MaixII-Dock, MaixPy3\n---\n\n在文档中看到 V831 可以用来实现人脸识别，于是就将按键也添加到人脸识别中。\n\n<!-- more -->\n\n\n实现一个可以通过按键进行控制的人脸识别，进行人脸信息的添加和删除控制\n## 源码\n\n```python\nfrom maix import nn, camera, image, display\nfrom maix.nn.app.face import FaceRecognize\nimport time\nfrom evdev import InputDevice\nfrom select import select\n\n\nscore_threshold = 70                            #识别分数阈值\ninput_size = (224, 224, 3)                      #输入图片尺寸\ninput_size_fe = (128, 128, 3)                   #输入人脸数据\nfeature_len = 256                               #人脸数据宽度\nsteps = [8, 16, 32]                             #\nchannel_num = 0                                 #通道数量\nusers = []                                      #初始化用户列表\nnames = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]  #人脸标签定义\nmodel = {                                                                                                                                   \n    \"param\": \"/home/model/face_recognize/model_int8.param\",\n    \"bin\": \"/home/model/face_recognize/model_int8.bin\"\n}\nmodel_fe = {\n    \"param\": \"/home/model/face_recognize/fe_res18_117.param\",\n    \"bin\": \"/home/model/face_recognize/fe_res18_117.bin\"\n}\n\n\nfor i in range(len(steps)):\n    channel_num += input_size[1] / steps[i] * (input_size[0] / steps[i]) * 2\nchannel_num = int(channel_num)     #统计通道数量\noptions = {                             #准备人脸输出参数\n    \"model_type\":  \"awnn\",\n    \"inputs\": {\n        \"input0\": input_size\n    },\n    \"outputs\": {\n        \"output0\": (1, 4, channel_num) ,\n        \"431\": (1, 2, channel_num) ,\n        \"output2\": (1, 10, channel_num) \n    },\n    \"mean\": [127.5, 127.5, 127.5],\n    \"norm\": [0.0078125, 0.0078125, 0.0078125],\n}\noptions_fe = {                             #准备特征提取参数\n    \"model_type\":  \"awnn\",\n    \"inputs\": {\n        \"inputs_blob\": input_size_fe\n    },\n    \"outputs\": {\n        \"FC_blob\": (1, 1, feature_len)\n    },\n    \"mean\": [127.5, 127.5, 127.5],\n    \"norm\": [0.0078125, 0.0078125, 0.0078125],\n}\nkeys = InputDevice('/dev/input/event0')\n\nthreshold = 0.5                                         #人脸阈值\nnms = 0.3                                               \nmax_face_num = 1                                        #输出的画面中的人脸的最大个数\nprint(\"-- load model:\", model)\nm = nn.load(model, opt=options)\nprint(\"-- load ok\")\nprint(\"-- load model:\", model_fe)\nm_fe = nn.load(model_fe, opt=options_fe)\nprint(\"-- load ok\")\nface_recognizer = FaceRecognize(m, m_fe, feature_len, input_size, threshold, nms, max_face_num)\n\ndef get_key():                                      #按键检测函数\n    r,w,x = select([keys], [], [],0)\n    if r:\n        for event in keys.read(): \n            if event.value == 1 and event.code == 0x02:     # 右键\n                return 1\n            elif event.value == 1 and event.code == 0x03:   # 左键\n                return 2\n            elif event.value == 2 and event.code == 0x03:   # 左键连按\n                return 3\n    return 0\n\ndef map_face(box,points):                           #将224*224空间的位置转换到240*240空间内\n    def tran(x):\n        return int(x/224*240)\n    box = list(map(tran, box))\n    def tran_p(p):\n        return list(map(tran, p))\n    points = list(map(tran_p, points))\n    return box,points\ndef darw_info(draw, box, points, disp_str, bg_color=(255, 0, 0), font_color=(255, 255, 255)):    #画框函数\n    box,points = map_face(box,points)\n    font_wh = image.get_string_size(disp_str)\n    for p in points:\n        draw.draw_rectangle(p[0] - 1, p[1] -1, p[0] + 1, p[1] + 1, color=bg_color)\n    draw.draw_rectangle(box[0], box[1], box[0] + box[2], box[1] + box[3], color=bg_color, thickness=2)\n    draw.draw_rectangle(box[0], box[1] - font_wh[1], box[0] + font_wh[0], box[1], color=bg_color, thickness = -1)\n    draw.draw_string(box[0], box[1] - font_wh[1], disp_str, color=font_color)\ndef recognize(feature):                                                                   #进行人脸匹配\n    def _compare(user):                                                         #定义映射函数\n        return face_recognizer.compare(user, feature)                      #推测匹配分数 score相关分数\n    face_score_l = list(map(_compare,users))                               #映射特征数据在记录中的比对分数\n    return max(enumerate(face_score_l), key=lambda x: x[-1])                #提取出人脸分数最大值和最大值所在的位置\n\ndef run():\n    img = camera.capture()                       #获取224*224*3的图像数据\n    AI_img = img.copy().resize(224, 224)\n    if not img:\n        time.sleep(0.02)\n        return\n    faces = face_recognizer.get_faces(AI_img.tobytes(),False)           #提取人脸特征信息\n    if faces:\n        for prob, box, landmarks, feature in faces:\n            key_val = get_key()\n            if key_val == 1:                                # 右键添加人脸记录\n                if len(users) < len(names):\n                    print(\"add user:\", len(users))\n                    users.append(feature)\n                else:\n                    print(\"user full\")\n            elif key_val == 2:                              # 左键删除人脸记录\n                if len(users) > 0:\n                    print(\"remove user:\", names[len(users) - 1])\n                    users.pop()\n                else:\n                    print(\"user empty\")\n\n            if len(users):                             #判断是否记录人脸\n                maxIndex = recognize(feature)\n\n                if maxIndex[1] > score_threshold:                                      #判断人脸识别阈值,当分数大于阈值时认为是同一张脸,当分数小于阈值时认为是相似脸\n                    darw_info(img, box, landmarks, \"{}:{:.2f}\".format(names[maxIndex[0]], maxIndex[1]), font_color=(0, 0, 255, 255), bg_color=(0, 255, 0, 255))\n                    print(\"user: {}, score: {:.2f}\".format(names[maxIndex[0]], maxIndex[1]))\n                else:\n                    darw_info(img, box, landmarks, \"{}:{:.2f}\".format(names[maxIndex[0]], maxIndex[1]), font_color=(255, 255, 255, 255), bg_color=(255, 0, 0, 255))\n                    print(\"maybe user: {}, score: {:.2f}\".format(names[maxIndex[0]], maxIndex[1]))\n            else:                                           #没有记录脸\n                darw_info(img, box, landmarks, \"error face\", font_color=(255, 255, 255, 255), bg_color=(255, 0, 0, 255))\n\n\n    display.show(img)\n\n\n\nif __name__ == \"__main__\":\n    import signal\n    def handle_signal_z(signum,frame):\n        print(\"APP OVER\")\n        exit(0)\n    signal.signal(signal.SIGINT,handle_signal_z)\n    while True:\n        run()\n\n```"}, "/news/MaixPy3/difference.html": {"title": "MaixPy 与 MaixPy3 的区别", "content": "---\ntitle: MaixPy 与 MaixPy3 的区别\nkeywords: MaixPy, MaixPy3, Python, Python3, MicroPython\ndesc: MaixPy 与 MaixPy3 的区别\ndate: 2022-03-07\ntags: MaixPy,MaixPy3\n---\n\n\n<!-- more -->\n\n## 区别是？\n\n因为使用 MaixPy 的同学可能有两类人群，一类是从 MicroPython 一路使用过来的，另一类是从 Python3 过来的，所以针对两边的差异，分别做一下说明。\n\n可以这样理解，它们都是专门为 AIoT 提供的 Python 开发环境，提供了各种各样的模块。\n\n- MaixPy 指的是基于 MicroPython 的环境制作的。\n\n- MaixPy3 指的是基于 Linux Python3 的环境制作的。\n\n> 前者是基于 MCU 无系统的，后者是基于 Linux 系统。\n\n除了基本的 Python3 语法一致，在提供的模块方面的存在着不小的差异。\n\n### Python3 与 MicroPython 的区别\n\n大多数时候，Python 的发展以 Python3 为主，以下列出一些与 Python3 的差异化信息。\n\n- MicroPython 和 Python3 在 Python 语法上保持高度的一致性，常用的标准语法命令都已经支持。\n\n- MicroPython 虽然只实现了 Python3 的标准库和容器库的一些部分，常见容器库有同类功能，但不同名的模块，但大多算法类的 Python 逻辑代码是可以拿来即用的。\n\n- MicroPython 兼容实现的 Python3 的异常机制、没有实现元类（metaclass）机制，独立的 GC 机制。\n\n- 在许当不同的硬件微芯片（最低在 nRF51）的移植上， MicroPython 代码接口缺乏一致性，呈现碎片化。\n\n- MicroPython 编译（mpy-corss）后得到的是 mpy ，而不是 Python3 的 pyc 文件。\n\n- MicroPython 在移植 Python3 代码时，经常缺少各种方法，所以要习惯寻找同类接口，而它们的使用方法除了看文档外就只能看源码。\n\n### 总结\n\n- MaixPy 相比 MaixPy3 功能要更简单（简陋）。\n- MaixPy 和 MaixPy3 的开发工具不同。\n- MaixPy 标准库（MicroPython）相比 MaixPy3 有一定的不足。\n- MaixPy 的外设驱动模块具体函数存在差异。\n- 不同的芯片执行效率有差异，MaixPy 和 MaixPy3 的有着不同的内存与性能消耗。\n\n> 如有更多欢迎补充。"}, "/news/index.html": {"title": "动态", "content": "---\n\ntitle: 动态\nkeywords: teedoc, 博客生成, 静态博客\ndesc: teedoc 静态博客页面生成\nshow_source: false\ndate: true\n\n---\n<div id=\"blog_list\"></div>"}, "/news/others/Python_call_so.html": {"title": "python3调用c/cpp的方法", "content": "---\ntitle: python3调用c/cpp的方法\nkeywords: python, c, cpp,\ndesc: python调用so\ndate: 2022-03-31\ntags: python, c, cpp\n---\n\n\n<!-- more -->\n\n原文链接：https://blog.csdn.net/springlustre/article/details/101177282\n作者：[springlustre](https://blog.csdn.net/springlustre?type=blog)\n有改动，仅供参考\n\npython中使用 ctypes 模块可以在python中直接调用C/C++。\n首先要将C/C++编译成动态库（.so)，然后python中调用即可。\n\n特别注意在调用C++函数需要在函数声明时，加入前缀 extern \"C\" ，这是因为C++支持函数重载功能，在编译时会改变函数名。在函数声明时，前缀extern \"C\"可以确保按C的方式进行编译。\n\n值得注意的是，一定要有函数输入输出类型的声明，int型不用转换，float和double类型需要进行转换；\nctypes中的变量类型与C中对应如下：\n\n| ctypes数据类型 | C数据类型     |\n| -------------- | ------------- |\n| c_char         | char          |\n| c_short        | short         |\n| c_int          | int           |\n| c_long         | long          |\n| c_float        | float         |\n| c_double       | double        |\n| c_void_p       | void          |\n| c_uint8        | unsigned char |\n\n使用方法：\n- 编写c++代码\n\n```cpp\n#include <iostream>\n#include <string>\n#include <cstdlib>\n#include <vector>\n#include <stdio.h>\n\n\nclass Test{\n    private:\n        double _calculate(int a, double b);\n    public:\n        double calculate(int a, double b, char c[], int * d, double * e, char ** f);\n};\n\ndouble Test::_calculate(int a, double b){\n    double res = a+b;\n    std::cout<<\"res: \"<<res<<std::endl;\n    return res;\n}\n\ndouble Test::calculate(int a, double b, char c[], int * d, double * e, char ** f){\n    std::cout<<\"a: \"<<a<<std::endl;\n    std::cout<<\"b: \"<<b<<std::endl;\n    std::cout<<\"c: \"<<c<<std::endl;\n    std::cout<<\"d: \"<<d[0]<<d[1]<<std::endl;\n    std::cout<<\"e: \"<<e[0]<<e[1]<<std::endl;\n    std::cout<<\"f: \"<<f[0]<<f[1]<<std::endl;\n    return this->_calculate(a, b);\n}\n\n\n// 封装C接口\nextern \"C\"{\n// 创建对象\n    Test* test_new(){\n        return new Test;\n    }\n    double my_calculate(Test* t, int a, double b, char c[], int * d, double * e, char ** f){\n        return t->calculate(a, b,c,d,e,f);\n    }\n}\n\n```\n- 将上面的代码编译成so文件\n\n> g++ -shared -Wl,-soname,test -o test.so -fPIC test.cpp\n\n- 使用python调用so文件\n\n```python\n# -*- coding: utf-8 -*-\nimport ctypes\n# 指定动态链接库\nlib = ctypes.cdll.LoadLibrary('./test.so')\n#需要指定返回值的类型，默认是int\nlib.my_calculate.restype = ctypes.c_double\n\nclass Test(object):\n    def __init__(self):\n        # 动态链接对象\n        self.obj = lib.test_new()\n\n    def calculate(self, a, b,c,d,e,f):\n        res = lib.my_calculate(self.obj, a, b,c,d,e,f)\n        return res\n\n#将python类型转换成c类型，支持int, float,string的变量和数组的转换\ndef convert_type(input):\n    ctypes_map = {int:ctypes.c_int,\n              float:ctypes.c_double,\n              str:ctypes.c_char_p\n              }\n    input_type = type(input)\n    if input_type is list:\n        length = len(input)\n        if length==0:\n            print(\"convert type failed...input is \"+input)\n            return null\n        else:\n            arr = (ctypes_map[type(input[0])] * length)()\n            for i in range(length):\n                arr[i] = bytes(input[i],encoding=\"utf-8\") if (type(input[0]) is str) else input[i]\n            return arr\n    else:\n        if input_type in ctypes_map:\n            return ctypes_map[input_type](bytes(input,encoding=\"utf-8\") if type(input) is str else input)\n        else:\n            print(\"convert type failed...input is \"+input)\n            return null\n\nif __name__ == '__main__':\n    t = Test()\n    A1\t= 123;\n    A2\t= 0.789;\n    A3\t= \"C789\";\n    A4\t= [456,789];\n    A5\t= [0.123,0.456];\n    A6\t= [\"A123\", \"B456\"];\n    print(t.calculate(convert_type(A1), convert_type(A2), convert_type(A3),convert_type(A4),convert_type(A5),convert_type(A6)))\n```"}, "/news/Lichee/RV/D1_RTL8723DS_Drivers/D1_RTL8723DS_Drivers.html": {"title": "D1 LicheeRV Dock 移植RTL8723DS驱动", "content": "---\ntitle: D1 LicheeRV Dock 移植RTL8723DS驱动\nkeywords: D1, RTL8723DS, 驱动\ndesc: RTL8723DS驱动移植\ndate: 2022-04-02\ntags: linux, D1\n---\n\n这里讲解怎样自己添加驱动\n\n<!-- more -->\n\n[原文链接](https://bbs.aw-ol.com/topic/994/d1-licheerv-dock-%E7%A7%BB%E6%A4%8Drtl8723ds%E9%A9%B1%E5%8A%A8)\n\n手动焊接RTL8723DS之后，现在开始移植驱动程序。\n\n先获取源码：https://github.com/lwfinger/rtl8723ds\n\n下载完成后，把驱动文件复制到 tina-d1-open\\lichee\\linux-5.4\\drivers\\net\\wireless\\rtl8723ds 里，没有rtl8723ds文件夹记得新建一个。\n\n修改tina-d1-open\\lichee\\linux-5.4\\drivers\\net\\wireless\\Makefile，加一行 \nobj-$(CONFIG_RTL8723DS) += rtl8723ds/\n\n![](./assets/rtl8723ds.png)\n\n修改tina-d1-open\\lichee\\linux-5.4\\drivers\\net\\wireless\\Kconfig，加一行 \nsource \"drivers/net/wireless/rtl8723ds/Kconfig\"\n\n![](./assets/Kconfig.png)\n\n修改tina-d1-open\\lichee\\linux-5.4\\drivers\\net\\wireless\\rtl8723ds\\os_dep\\linux\\os_intfs.c；\n加一行\nMODULE_IMPORT_NS(VFS_internal_I_am_really_a_filesystem_and_am_NOT_a_driver);\n\n![](./assets/os_intfs.png)\n\n修改tina-d1-open\\lichee\\linux-5.4\\drivers\\net\\wireless\\rtl8723ds\\os_dep\\linux\\rtw_cfgvendor.c\n在每一行.policy = VENDOR_CMD_RAW_DATA, 下面加上 .maxattr = 1,\n\n![](./assets/rtw_cfgvendor.png)\n\n修改tina-d1-open\\target\\allwinner\\d1-lichee_rv_dock\\modules.mk，增加以下内容：\n\n![](./assets/modules.png)\n\n（其中的d1-lichee_rv_dock 是我的板级配置，请选择自己的板级配置比如d1-nezha，如下图）\n\n![](./assets/borad_config.png)\n\n进入内核配置，勾选Realtek 8723D SDIO or SPI WiFi为Module（ < M > 不是 < * > ）\n\n```menuconfig\nmake kernel_menuconfig\n\nDevice Drivers ->\n     Network device support -> \n           Wireless LAN -> \n                  <M>   Realtek 8723D SDIO or SPI WiFi\n```\n\n进入Tina配置，勾选相关驱动\n\n```bash\nmake menuconfig\n\nFirmware  ->\n     <*> r8723ds-firmware.............................. RealTek RTL8723DS firmware\n\nKernel modules -> \n     Wireless Drivers  ->\n        <*> kmod-net-rtl8723ds........................... RTL8723DS support (staging)\n```\n\n保存，编译，打包\n\n```bash\nmake -j8\npack\n```\n\n烧录后就能看到\n\n![](./assets/apperance.jpg)"}}